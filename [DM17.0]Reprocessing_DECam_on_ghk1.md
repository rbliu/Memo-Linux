__$$$$$ Redundant file $$$$$__

_This instruction is based on the [Wiki page of CFHTLS-reprocessing](https://github.com/LSSTDESC/ReprocessingTaskForce/wiki) and [another obs_decam tutorial documentation](https://www.overleaf.com/read/vmnstztyfbht). In addition to giving credit to the editors of the Wiki page, I also greatly appreciate help from Dominique Boutigny, Shenming Fu, Jim Bosch, Dominique Fouchez, Robert Lupton, Simon Krughoff, Nicolas Chotard, Johann Cohen-Tanugi, Meredith Rawls, Kian-Tat Lim, Colin Slater, Chris Waters, John Parejko, and all the experts in DM team and the LSST Community. This instruction is only used as personal technical notes which belongs to Ian Dell'Antonio's group, and by no means to be published. Any code in this instruction is open-source and without any warranty._

# (In construction) DECam Reprocessing on `ghk1`


## 1. Login to `ghk1`

ssh to `ghk1` and setup DMstack. We have a `v17.0` version of DMstack installed.

**Sample config files can be found at https://github.com/LSSTDESC/ReprocessingTaskForce/tree/master/config**

```
ssh ghk1
bash
source /net/mangrove/export/data/astro/lsst_stack_v17_0_1/loadLSST.bash
setup lsst_distrib
```
If you have permission issue, send me an email (byliu1990(at)gmail.com)

You can process either DECam Community Pipeline products (instrumental calibrated images) or raw data. As for now, the masks in the CP products may cause some issue in `processCcd`. So we suggest using raw data.

Suppose the working directory is named as `DECam_repo`. In this directory, create some sub-directories:
```
mkdir raw_data config MasterCal_bias MasterCal_flat
mkdir -p DATA/CALIB/2013-01-01
```

where `DATA` is the main directory for processing data;

`raw_data` has all the raw DECam images (`.fits.fz`);

`config` is where you store all the config files; you can find all necessary config files in [this repository](https://github.com/rbliu/Memo-Linux/blob/master/DECam-config/v17.0)


## 2. Setup astrometry reference

We have Gaia/Pan-STARRS-1/SDSS reference catalogs for astrometry and photometry calibration. By default, PS1 is used as both astrometry and photometry calibration. You can also choose Gaia catalog for astrometry.

```
ca DATA
ln -s /export/rliu/refcats/htm_baseline ref_cats
```


## 3. Ingest Images and Master Calibration files

First, ingest the raw data:
```
ingestImagesDecam.py DATA --filetype raw raw_data/*.fz --mode link
```
The sub-directory is named as `DATA/CALIB/2013-01-01`. But if your raw data is even older, you will need to name it as an earlier date.

Then, ingest defect data:
```
cp -v /net/mangrove/export/data2/astro/decam_defect/*.fits DATA/CALIB/2013-01-01/
ingestCalibs.py DATA --calib DATA/CALIB --calibType defect --validity 9999 DATA/CALIB/2013-01-01/*.fits --mode skip
```

You need to download correct flat and bias(zero) master calibration data from NOAO archive, and put them in `MasterCal_flat` and `MasterCal_bias` respectively:
```
ingestCalibs.py DATA --calib DATA/CALIB MasterCal_flat/*fci*fits.fz --mode link --validity 9999
ingestCalibs.py DATA --calib DATA/CALIB MasterCal_bias/*zci*fits.fz --mode link --validity 9999
```

Fringe is only used for z-band data:
```
mkdir -p DATA/CALIB/FRINGE/2013-01-01/z
cp -v /net/mangrove/export/data2/astro/decam_fringe/DECamMasterCal_56876/fringecor/*_z_* .

rename "DECam_Master_20131115v1-zG_ci_z_" "FRINGE-2013-11-15-" DECam_Master_20131115v1-zG_ci_z_*.fits
mv -v FRINGE-2013-11-15*fits DATA/CALIB/FRINGE/2013-01-01/z/

ingestCalibs.py DATA --calib DATA/CALIB --calibType fringe --validity 9999 DATA/CALIB/FRINGE/2013-01-01/z/* --mode skip
```


## 4. processCcd

We can process single CCD using:
```
processCcd.py DATA --rerun processCcdOutputs --id visit=802342 ccdnum=35 -C config/processCcdConfig.py -c calibrate.doAstrometry=True calibrate.doPhotoCal=True
```
(usually, we run quick tests on single CCDs to make sure DM stack and the config file are working appropriately)

Or process all exposures for one filter:
```
processCcd.py DATA @g.list --calib DATA/CALIB --rerun processCcdOutputs -C config/processCcdConfig.py -c calibrate.doAstrometry=True calibrate.doPhotoCal=True -j 4
```
where `g.list` has
```
--id visit=431542 ccdnum=1^3..60^62
--id visit=511246 ccdnum=1^3..60^62
--id visit=802342 ccdnum=1^3..60
```

and `-j 4` means using 4 cores (or threads) for parallel -- modify this number according to your machine.

**Note: If there is no `DATA/rerun/processCcdOutputs` directory before running `processCcd.py`, it will be created; if there is already a `DATA/rerun/processCcdOutputs` directory with previous processed data, `processCcd.py` will overwrite output into it.**

The output repository usually contains:
```
calexp	config	icSrc  metadata  repositoryCfg.yaml  schema  src  srcMatch
```

where `calexp` and `src` are two important outputs.

`calexp` are calibrated exposures (Multi-Extension FITS) with these extensions:
* image
* mask
* variance

`src` are source catalogs (FITS table), which include all measurements.

**Note: These images and measurements are just preliminary results from `processCcd.py`. To obtain advanced results, you need to run `processCcd.py` for all the filters and go through the following steps until forced photometry.**



## 5. Coadd

### 5.1 Create a skymap

To determine the skymap coordinates

```
makeDiscreteSkyMap.py DATA @g.list @r.list --rerun processCcdOutputs:skyMap -C config/makeDiscreteSkyMapConfig.py
```

and its output should look like:
```
makeDiscreteSkyMap INFO: tract 0 has corners (150.596, -1.508), (147.674, -1.508), (150.596, 1.412), (147.674, 1.412) (RA, Dec deg) and 9 x 9 patches
```

### 5.2 Identify the list of (tract,patch)

From the output of the previous step, get the coordinates of the lower left and upper right corners in order to pass them to the following command:

```
reportPatches.py DATA/rerun/skyMap/ --config raDecRange="147.674, -1.508, 150.596, 1.412" --id tract=0 patch=0,0 filter=r > patches.txt
```

where `--id tract=0 patch=0,0` is meaningless but mandatory. In some new versions of DM stack, the reportPatches step may also write some extra rows to patches.txt. So, double check patches.txt and make sure they only contain useful rows like:
```
--id tract=0 patch=0,0
--id tract=0 patch=0,1
```

Then we need to modify a little bit the `patches.txt` file:
```
sed -e 's/^/--id filter=g /' patches.txt > patches_g.txt
sed -e 's/^/--id filter=r /' patches.txt > patches_r.txt
```

LSST processed data have the (tract,patch) layout. Usually, for one exposure, we have its `tract=0` and `patch=0,0` to `9,9`.

### 5.3 Jointcal

```
jointcal.py DATA --rerun skyMap:jointcal @g.list
jointcal.py DATA --rerun skyMap:jointcal @r.list
```


### 5.4 Warp images to adjust them to the sky map patches

Create two new list files:
```
sed 's/id/selectId/g' g.list > select_g.list
sed 's/id/selectId/g' r.list > select_r.list
```

and runï¼š
```
makeCoaddTempExp.py DATA --rerun jointcal:coadd @select_g.list @patches_g.txt --config doApplyUberCal=True makePsfMatched=True -j 4
makeCoaddTempExp.py DATA --rerun jointcal:coadd @select_r.list @patches_r.txt --config doApplyUberCal=True makePsfMatched=True -j 4
```

This will create one warped image for each visit/CCD contributing to a each given patch/tract.

It is safe to append `--timeout 9999999` option to avoid timeout error.

Now, there should be warped pieces of images under
```
./DATA/rerun/coadd/deepCoadd/g/0/0,0tempExp/ ~ 9,9tempExp/
```


### 5.5 Assemble the coadded images

Assemble the temp exposures for each patch:
```
assembleCoadd.py --warpCompare DATA --rerun coadd @select_g.list @patches_g.txt -j 4
assembleCoadd.py --warpCompare DATA --rerun coadd @select_r.list @patches_r.txt -j 4
```

The assebled images are:
```
./DATA/rerun/coadd/deepCoadd/g/0/0,0.fits ~ 9,9.fits
```



## 6. Multi-band processing

Repeat the coadd steps for each filter. And go through the multi-band processing steps for one patch:
```
detectCoaddSources.py DATA --rerun coadd:coaddMeasure @patches_g.txt -j 4
detectCoaddSources.py DATA --rerun coadd:coaddMeasure @patches_r.txt -j 4

mergeCoaddDetections.py DATA --rerun coaddMeasure --id filter=g^r

deblendCoaddSources.py DATA --rerun coaddMeasure --id filter=g -j 4
deblendCoaddSources.py DATA --rerun coaddMeasure --id filter=r -j 4

measureCoaddSources.py DATA --rerun coaddMeasure:coaddMeasure2 --id filter=g -C config/measureCoaddSourcesConfig.py -j 4
measureCoaddSources.py DATA --rerun coaddMeasure:coaddMeasure2 --id filter=r -C config/measureCoaddSourcesConfig.py -j 4

mergeCoaddMeasurements.py DATA --rerun coaddMeasure2 --id filter=g^r -j 4
```

Or use the `--id` option to run any single step on a given patch.

* `detectCoaddSources.py` = source detection in the deep-coadded images. Repeat this step for all bands you have coadded.
* `mergeCoaddDetections.py` = merges the detected sources from multi-band. Connect all bands from the previous step with `^` in the `--id` option.
* `deblendCoaddSources.py` = deblending of the deep-coadded sources. Again, you need to repeat this step for all band.
* `measureCoaddSources.py` = shape measurement of the detected sources. Repeat this step for all bands you have coadded.
* `mergeCoaddMeasurements.py` = use the best measured band as the reference band for each source, which will be used in the following `forcedPhotometry` step. Connect all bands from the previous step with `^` in the `--id` option.

You should expect the outputs of each step (in `deepCoadd-results` directory):

 |         Step           |       Output Samples       |
 |:----------------------:|:---------------------------:|
 | detectCoaddSources     |  `bkgd-g-0-5,5.fits` + `calexp-g-0-5,5.fits` + `det-g-0-5,5.fits` |
 | mergeCoaddDetections   |  `mergeDet-0-5,5.fits` |
 | measureCoaddSources    |  `meas-g-0-5,5.fits`   |
 | mergeCoaddMeasurements |  `ref-0-5,5.fits`      |

where `meas-g-0-5,5.fits` is the coadd measurements for one filter in one patch.

Each coadd source is detected / deblended / measured using `CModel` -- make sure you have it in the `measureCoaddSourcesConfig.py` config file:
```
import lsst.meas.modelfit
import lsst.shapelet
config.measurement.plugins.names |= ["modelfit_DoubleShapeletPsfApprox", "modelfit_CModel"]
config.measurement.slots.modelFlux = "modelfit_CModel"
```

The multiband processing guarantees that if 1 source is identified and measured in 1 band, there is also corresponding sources in the other bands.

`CModel` fits an exponential and a de Vaucouleur separately, then fit a linear combination of the two while holding the ellipse parameters fixed at the best fit values from an independent fitting.


## 7. Forced photometry

In forced photometry the source detection and galaxy shape measurement is performed in a reference band and the photometry is measured in the other bands assuming that the same galaxy shape (even if it is not detected).

It can be run at the CCD level (`forcedPhotCcd.py`) or at the coadd level (`forcedPhotCoadd.py`).

To run forced photometry on one patch:
```
forcedPhotCoadd.py DATA --rerun coaddMeasure2:coaddForcedPhot --id filter=g -C config/forcedPhotCoaddConfig.py -j 4
forcedPhotCoadd.py DATA --rerun coaddMeasure2:coaddForcedPhot --id filter=r -C config/forcedPhotCoaddConfig.py -j 4
```



## Reference

- [LSST DESC Reprocessing Task Force Wiki page](https://github.com/LSSTDESC/ReprocessingTaskForce/wiki)
- [Jim Bosch, DMTN-023: Pipeline Command-Line Drivers](https://dmtn-023.lsst.io/#)
- [Getting started with the LSST Science Pipelines](https://pipelines.lsst.io/v/DM-14044/getting-started/index.html#getting-started-tutorial)
